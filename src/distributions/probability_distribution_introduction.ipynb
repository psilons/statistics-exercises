{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction to Probability Distributions\n",
    "\n",
    "A probability space is the tuple (Ω, ℱ, P) with\n",
    "- a sample space Ω, such as {H, T} for coin flips (head or tail)\n",
    "- an event space ℱ, such as {H, T, HH, HT} for coin flips\n",
    "- a probability function P defined on the ℱ, such as 0.5 for H and T.\n",
    "\n",
    "## Probability Mass Function(PMF)\n",
    "\n",
    "The PMF of a random variable $X$ is\n",
    "\n",
    "$\\begin{align*}\\quad\\quad\n",
    "p_X(x) = \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        P(X=x), & \\text{if } x \\in ℱ \\\\\n",
    "        0,      &  \\text{else} \\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "\\end{align*}$\n",
    "\n",
    "It satisfies:\n",
    "1. $ \\sum_{x \\in ℱ}p_X(x) = 1 $\n",
    "2. $ p_X(x) \\geqslant 0 $,  for all $x$ in ℱ\n",
    "\n",
    "## Probability Density Function(PDF)\n",
    "\n",
    "The density function $f(x)$ of a probability space is the graph of ℱ - P\n",
    "\n",
    "![discrete](discrete_pdf.png)\n",
    "\n",
    "$f(x)$ satisfies\n",
    "1. $ P(X \\in A) = \\int_A{f(x)}dx $, where $A \\subseteq F$.\n",
    "2. $ \\int_F{f(x)}dx = 1$\n",
    "3. $1 > f(x) > 0 \\text{ for } x \\in F$ or $0$ for $x \\notin F$\n",
    "\n",
    "Another way to write $f(x)$ is\n",
    "\n",
    "$\\begin{align*}\\quad\\quad\n",
    "P(a < X \\leqslant b) = \\int_a^bf(x)dx\n",
    "\\end{align*}$\n",
    "\n",
    "Intutively, the probability is the area under $f(x)$.\n",
    "\n",
    "## Cumulative Distribution Function(CDF)\n",
    "\n",
    "In [Wiki](https://en.wikipedia.org/wiki/Cumulative_distribution_function), the CDF function $F(x)$ is defined as\n",
    "$\\begin{align*}\\quad\\quad\n",
    "F_X(x) = P(X \\leqslant x)\n",
    "\\end{align*}$\n",
    "\n",
    "This means\n",
    "$\\begin{align*}\\quad\\quad\n",
    "P(a < X \\leqslant b) = F_X(b) - F_X(a)\n",
    "\\end{align*}$\n",
    "\n",
    "The PDF $f(x)$ can be expressed as\n",
    "$\\begin{align*}\\quad\\quad\n",
    "f(x) = \\frac{dF(x)}{dx}\n",
    "\\end{align*}$\n",
    "\n",
    "and\n",
    "$\\begin{align*}\\quad\\quad\n",
    "F_X(x) = \\int_{-\\infty}^x f(t)dt\n",
    "\\end{align*}$\n",
    "\n",
    "$F(x)$ satisfies:\n",
    "1. $F(x) \\leqslant F(y)$ for $ -\\infty < x < y < \\infty $\n",
    "2. $ \\lim\\limits_{x \\to -\\infty} F(x) = 0 $ and $ \\lim\\limits_{x \\to \\infty} F(x) = 1 $\n",
    "\n",
    "## Complementary CDF(CCDF)\n",
    "\n",
    "CCDF is defined as $ \\overline{F}_X(x) = 1 - F_X(x) $. Sometimes it is called survivor function. It describes the tail distribution.\n",
    "\n",
    "## Expectation and Variance\n",
    "\n",
    "The expectation of an RV X is the weighted average with probabilities.\n",
    "$\\begin{align*}\\quad\\quad\n",
    "\\mu = \\mathbb{E}[X] = \\int_\\mathbb{R}xf(x)dx\n",
    "\\end{align*}$\n",
    "\n",
    "Property: $ \\mathbb{E}[aX + b] = a\\mathbb{E}[X] + b $\n",
    "\n",
    "The Variance of an RV X is $ Var(X) = \\mathbb{E}\\Big[(X - \\mathbb{E}[X])^2\\Big] $\n",
    "\n",
    "The Standard Deviation of an RV X is $ \\sigma = std(X) = \\sqrt{Var(X)} $\n",
    "\n",
    "Properties:\n",
    "1. $ Var(X) = \\mathbb{E}[X^2] - \\Big(\\mathbb{E}[X]\\Big)^2 $\n",
    "2. $ Var(a) = 0 $ for constant $a$\n",
    "3. $ Var(aX + b) = a^2Var(X) $\n",
    "4. Markov inequality: $ P(X \\geqslant a) \\leqslant \\frac{\\mathbb{E}[X]}{a} $\n",
    "\n",
    "### Covariance and Correlation\n",
    "- https://en.wikipedia.org/wiki/Covariance\n",
    "- https://en.wikipedia.org/wiki/Correlation\n",
    "\n",
    "## Moments\n",
    "\n",
    "### Definitions\n",
    "The kth moment of an RV X is\n",
    "$\\begin{align*}\\quad\\quad\n",
    "m_k = \\mathbb{E}[X^k] = \\int_{-\\infty}^{\\infty}x^kf(x)dx\n",
    "\\end{align*}$\n",
    "\n",
    "The kth central moment(or moment around the mean) is\n",
    "$\\begin{align*}\\quad\\quad\n",
    "\\overline{m}_k = \\mathbb{E}\\Big[(X - \\mu)^k\\Big] = \\int_{-\\infty}^{\\infty}(x - \\mu)^kf(x)dx\n",
    "\\end{align*}$\n",
    "\n",
    "The kth standard central moment is\n",
    "$\\begin{align*}\\quad\\quad\n",
    "\\tilde{m}_k = \\frac{\\overline{m}_k}{\\sigma^k\n",
    "\\end{align*}$\n",
    "\n",
    "### First 4 moments\n",
    "- 1st moment is the expectation, 1st central moment and standard central moment is $0$. It measures the central value.\n",
    "- 2nd moment is the variance/dispersion - small variance means more similarity, i.e., more close to mean.\n",
    "- 3rd moment is the skewness - measure the asymmetry around the peak. It's often approximate by $(mean - median) / std$\n",
    "    - positive - fat long tail\n",
    "    - negative - thin long tail\n",
    "- 4th moment is the kurtosis - measure the flatness\n",
    "    - positive values - sharp peak\n",
    "    - negative values - slow varying\n",
    "\n",
    "More details:\n",
    "- Explain moments: https://gregorygundersen.com/blog/2020/04/11/moments/\n",
    "- https://stats.stackexchange.com/questions/123251/intuition-for-moments-about-the-mean-of-a-distribution\n",
    "- https://stats.stackexchange.com/questions/17595/whats-so-moment-about-moments-of-a-probability-distribution\n",
    "- https://mathoverflow.net/questions/3525/when-are-probability-distributions-completely-determined-by-their-moments\n",
    "\n",
    "## Moment Generating Functions\n",
    "In general\n",
    "\n",
    "$\\begin{align*}\\quad\\quad\n",
    "\\mathbb{E}[g(X)] = \\int_{-\\infty}^{\\infty}g(x)f(x)dx\n",
    "\\end{align*}$\n",
    "\n",
    "So $f(x)$ is a kernel function satisfying\n",
    "\n",
    "$\\begin{align*}\\quad\\quad\n",
    "\\mathbb{E}[1] = \\int_{-\\infty}^{\\infty}f(x)dx = 1\n",
    "\\end{align*}$\n",
    "\n",
    "The moment generating function (MGF) is\n",
    "\n",
    "$\\begin{align*}\\quad\\quad\n",
    "M_X(t) = \\mathbb{E}[e^{tX}] = \\int_{-\\infty}^{\\infty}e^{tx}f(x)dx\n",
    "\\end{align*}$\n",
    "\n",
    "More details:\n",
    "- http://www.milefoot.com/math/stat/rv-moments.htm\n",
    "- https://brianzhang01.github.io/2018/04/distributions-with-sympy/\n",
    "\n",
    "## KL Divergence\n",
    "Compare 2 distributions\n",
    "- https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n",
    "\n",
    "\n",
    "## References:\n",
    "- https://en.wikipedia.org/wiki/Kernel_(statistics)\n",
    "- https://en.wikipedia.org/wiki/Mathematical_Alphanumeric_Symbols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}