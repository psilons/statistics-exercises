{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction to Probability Distributions\n",
    "\n",
    "A probability space is the tuple (Ω, ℱ, P) with\n",
    "- a sample space Ω, such as {H, T} for coin flips (head or tail)\n",
    "- an event space ℱ, such as {H, T, HH, HT} for coin flips\n",
    "- a probability function P defined on the ℱ, such as 0.5 for H and T.\n",
    "\n",
    "## Probability Mass Function(PMF)\n",
    "\n",
    "The PMF of a random variable $X$ is\n",
    "$$ p_X(x) = \\begin{cases}\n",
    "               P(X=x), &\\ \\text{if $x$ \\in ℱ} \\\\\n",
    "               0,      &\\ \\text{else}\n",
    "            \\end{cases}\n",
    "$$\n",
    "\n",
    "It satisfies:\n",
    "1. $ \\sum_{x \\in ℱ}p_X(x) = 1 $\n",
    "2. $ p_X(x) \\geqslant 0 $,  for all $x$ in ℱ\n",
    "\n",
    "## Probability Density Function(PDF)\n",
    "\n",
    "The density function $f(x)$ of a probability space is the graph of ℱ - P\n",
    "\n",
    "![discrete](discrete_pdf.png)\n",
    "\n",
    "$f(x)$ satisfies\n",
    "1. $ P(X \\in A) = \\int_A{f(x)}dx $, where $A \\subseteq F$.\n",
    "2. $ \\int_F{f(x)}dx = 1$\n",
    "3. $1 > f(x) > 0$ for $x \\in F$ or $0$ for $x \\notin F$\n",
    "\n",
    "Another way to write $f(x)$ is\n",
    "$$ P(a < X \\leqslant b) = \\int_a^b{f(x)dx $$\n",
    "Intutively, the probability is the area under $f(x)$.\n",
    "\n",
    "## Cumulative Distribution Function(CDF)\n",
    "\n",
    "In [Wiki](https://en.wikipedia.org/wiki/Cumulative_distribution_function), the CDF function $F(x)$ is defined as\n",
    "$$ F_X(x) = P(X \\leqslant x) $$\n",
    "This means\n",
    "$$ P(a < X \\leqslant b) = F_X(b) - F_X(a) $$\n",
    "The PDF $f(x)$ can be expressed as\n",
    "$$ f(x) = \\frac{dF(x)}{dx} $$\n",
    "and\n",
    "$$ F_X(x) = \\int_{-\\infty}^x f(t)dt $$\n",
    "\n",
    "$F(x)$ satisfies:\n",
    "1. $F(x) \\leqslant F(y)$ for $ -\\infty < x < y < \\infty $\n",
    "2. $ \\lim\\limits_{x \\to -\\infty} F(x) = 0 $ and $ \\lim\\limits_{x \\to \\infty} F(x) = 1 $\n",
    "\n",
    "## Complementary CDF(CCDF)\n",
    "\n",
    "CCDF is defined as $ \\overline{F}_X(x) = 1 - F_X(x) $. Sometimes it is called survivor function. It describes the tail distribution.\n",
    "\n",
    "## Expectation and Variance\n",
    "\n",
    "The expectation of an RV X is the weighted average with probabilities.\n",
    "$$ \\mu = \\mathbb{E}[X] = \\int_\\mathbb{R}xf(x)dx $$\n",
    "\n",
    "Property: $$ \\mathbb{E}[aX + b] = a\\mathbb{E}[X] + b $$\n",
    "\n",
    "The Variance of an RV X is $ Var(X) = \\mathbb{E}\\Big[(X - \\mathbb{E}[X])^2\\Big] $\n",
    "\n",
    "The Standard Deviation of an RV X is $ \\sigma = std(X) = \\sqrt{Var(X)} $\n",
    "\n",
    "Properties:\n",
    "1. $ Var(X) = \\mathbb{E}[X^2] - \\Big(\\mathbb{E}[X]\\Big)^2 $\n",
    "2. $ Var(a) = 0 $ for constant $a$\n",
    "3. $ Var(aX + b) = a^2Var(X) $\n",
    "4. Markov inequality: $ P(X \\geqslant a) \\leqslant \\frac{\\mathbb{E}[X]}{a} $\n",
    "\n",
    "### Covariance and Correlation\n",
    "- https://en.wikipedia.org/wiki/Covariance\n",
    "- https://en.wikipedia.org/wiki/Correlation\n",
    "\n",
    "## Moments\n",
    "\n",
    "### Definitions\n",
    "The kth moment of an RV X is\n",
    "$$ m_k = \\mathbb{E}[X^n] = \\int_{-\\infty}^{\\infty}x^kf(x)dx $$\n",
    "\n",
    "The kth central moment(or moment around the mean) is\n",
    "$$ \\overline{m}_k = \\mathbb{E}\\Big[(X - \\mu)^k\\Big] = \\int_{-\\infty}^{\\infty}(x - \\mu)^kf(x)dx$$\n",
    "\n",
    "The kth standard central moment is\n",
    "$$ \\tilde{m}_k = \\frac{\\overline{m}_k}{\\sigma^k $$\n",
    "\n",
    "### First 4 moments\n",
    "- 1st moment is the expectation, 1st central moment and standard central moment is $0$. It measures the central value.\n",
    "- 2nd moment is the variance/dispersion - small variance means more similarity, i.e., more close to mean.\n",
    "- 3rd moment is the skewness - measure the asymmetry around the peak. It's often approximate by $(mean - median) / std$\n",
    "    - positive - fat long tail\n",
    "    - negative - thin long tail\n",
    "- 4th moment is the kurtosis - measure the flatness\n",
    "    - positive values - sharp peak\n",
    "    - negative values - slow varying\n",
    "\n",
    "More details:\n",
    "- Explain moments: https://gregorygundersen.com/blog/2020/04/11/moments/\n",
    "- https://stats.stackexchange.com/questions/123251/intuition-for-moments-about-the-mean-of-a-distribution\n",
    "- https://stats.stackexchange.com/questions/17595/whats-so-moment-about-moments-of-a-probability-distribution\n",
    "- https://mathoverflow.net/questions/3525/when-are-probability-distributions-completely-determined-by-their-moments\n",
    "\n",
    "## Moment Generating Functions\n",
    "- http://www.milefoot.com/math/stat/rv-moments.htm\n",
    "\n",
    "\n",
    "## KL Divergence\n",
    "Compare 2 distributions\n",
    "- https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n",
    "\n",
    "\n",
    "## References:\n",
    "- https://en.wikipedia.org/wiki/Kernel_(statistics)\n",
    "- https://en.wikipedia.org/wiki/Mathematical_Alphanumeric_Symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}